---
title: Quickstart
description: Get started with Moonshine Voice in minutes
---

Get up and running with Moonshine Voice in just a few steps. This guide will show you the fastest path to transcribing speech.

## Quick Start with Python

<Steps>
  <Step title="Install Moonshine Voice">
    Install the Python package using pip:
    
    ```bash
    pip install moonshine-voice
    ```
  </Step>
  
  <Step title="Run microphone transcription">
    Start transcribing from your microphone with one command:
    
    ```bash
    python -m moonshine_voice.mic_transcriber --language en
    ```
    
    Speak into your microphone and watch the transcription appear in real-time!
  </Step>
</Steps>

## Your First Python Program

Here's a complete example that transcribes an audio file:

```python
from moonshine_voice import Transcriber, ModelArch, get_model_for_language, load_wav_file

# Download and get the model
model_path, model_arch = get_model_for_language("en")

# Load audio file
audio_data, sample_rate = load_wav_file("speech.wav")

# Create transcriber
transcriber = Transcriber(
    model_path=model_path,
    model_arch=model_arch
)

# Transcribe
transcript = transcriber.transcribe_without_streaming(audio_data, sample_rate)

# Print results
for line in transcript.lines:
    print(f"[{line.start_time:.2f}s] {line.text}")

transcriber.close()
```

## Live Microphone Transcription

For real-time transcription with updates as you speak:

```python
from moonshine_voice import MicTranscriber, ModelArch, TranscriptEventListener

class PrintListener(TranscriptEventListener):
    def on_line_text_changed(self, event):
        # Print updates in real-time
        print(f"\\r{event.line.text}", end="", flush=True)
    
    def on_line_completed(self, event):
        # Print final version
        print(f"\\n\u2713 {event.line.text}")

# Get model
from moonshine_voice import get_model_for_language
model_path, model_arch = get_model_for_language("en")

# Create microphone transcriber
transcriber = MicTranscriber(
    model_path=model_path,
    model_arch=model_arch
)

# Add listener
transcriber.add_listener(PrintListener())

# Start listening
print("Listening... Press Ctrl+C to stop")
try:
    transcriber.start()
    while True:
        pass  # Keep running
except KeyboardInterrupt:
    transcriber.stop()
    print("\\nStopped")
```

## Voice Commands

Recognize voice commands using semantic matching:

```python
from moonshine_voice import MicTranscriber, IntentRecognizer, get_model_for_language, get_embedding_model

# Get models
asr_model_path, asr_model_arch = get_model_for_language("en")
embedding_model_path, embedding_model_arch = get_embedding_model("gemma-300m", "q4")

# Create intent recognizer
recognizer = IntentRecognizer(
    model_path=embedding_model_path,
    model_arch=embedding_model_arch,
    threshold=0.7
)

# Register commands
def on_lights_on(trigger, utterance, similarity):
    print(f"Turning lights ON (confidence: {similarity:.0%})")

def on_lights_off(trigger, utterance, similarity):
    print(f"Turning lights OFF (confidence: {similarity:.0%})")

recognizer.register_intent("turn on the lights", on_lights_on)
recognizer.register_intent("turn off the lights", on_lights_off)

# Create transcriber and attach recognizer
transcriber = MicTranscriber(
    model_path=asr_model_path,
    model_arch=asr_model_arch
)

transcriber.add_listener(recognizer)

# Start listening for commands
print("Voice command system ready")
print("Try saying: 'Please turn on the lights' or 'Switch off the lights'")
transcriber.start()
```

The semantic matching understands variations:
- "turn on the lights" → Matches perfectly
- "switch on the lights" → Also matches
- "lights on please" → Matches
- "illuminate the room" → Matches with lower confidence

## Quick Start: Other Platforms

<Tabs>
  <Tab title="iOS">
    1. Download the [iOS examples](https://github.com/moonshine-ai/moonshine/releases/latest/download/ios-examples.tar.gz)
    2. Extract and open `Transcriber/Transcriber.xcodeproj` in Xcode
    3. Build and run on your device or simulator
  </Tab>
  
  <Tab title="Android">
    1. Download the [Android examples](https://github.com/moonshine-ai/moonshine/releases/latest/download/android-examples.tar.gz)
    2. Extract and open the `Transcriber` folder in Android Studio
    3. Build and run on your device or emulator
  </Tab>
  
  <Tab title="macOS">
    1. Download the [macOS examples](https://github.com/moonshine-ai/moonshine/releases/latest/download/macos-examples.tar.gz)
    2. Extract and open `MicTranscription/MicTranscription.xcodeproj` in Xcode
    3. Build and run
  </Tab>
  
  <Tab title="Linux">
    1. Clone or download the repository
    2. Build the C++ core:
       ```bash
       cd core
       mkdir build && cd build
       cmake ..
       cmake --build .
       ./moonshine-cpp-test
       ```
  </Tab>
  
  <Tab title="Windows">
    1. Download the [Windows examples](https://github.com/moonshine-ai/moonshine/releases/latest/download/windows-examples.tar.gz)
    2. Extract and open `cli-transcriber\\cli-transcriber.vcxproj` in Visual Studio
    3. Install Python package for model downloading:
       ```batch
       pip install moonshine-voice
       python -m moonshine_voice.download --language en
       ```
    4. Build and run in Visual Studio
  </Tab>
</Tabs>

## Troubleshooting

<Accordion title="No audio detected">
  - Check microphone permissions for your terminal/app
  - Verify microphone is working with other apps
  - Try adjusting VAD threshold:
    ```python
    options = {"vad_threshold": "0.3"}
    transcriber = Transcriber(model_path=path, options=options)
    ```
</Accordion>

<Accordion title="Poor transcription quality">
  - Use a higher quality model (SMALL_STREAMING or MEDIUM_STREAMING)
  - Ensure audio is clear with minimal background noise
  - Check audio format is mono PCM
  - Enable debug logging:
    ```python
    options = {"save_input_wav_path": ".", "log_output_text": "true"}
    ```
</Accordion>

<Accordion title="Model download fails">
  - Check internet connection
  - Ensure you have disk space (~100-500MB per model)
  - Set custom cache location:
    ```bash
    export MOONSHINE_VOICE_CACHE=/path/to/cache
    python -m moonshine_voice.download --language en
    ```
</Accordion>

## Next Steps

<CardGroup cols={2}>
  <Card title="Installation guide" icon="download" href="/installation">
    Detailed installation for all platforms
  </Card>
  
  <Card title="Python API" icon="code" href="/api/python/transcriber">
    Complete API reference
  </Card>
  
  <Card title="Concepts" icon="brain" href="/concepts/architecture">
    Understand how Moonshine works
  </Card>
  
  <Card title="Examples" icon="book-open" href="/resources/examples">
    Explore example projects
  </Card>
</CardGroup>

<Tip>
  Join our [Discord community](https://discord.gg/27qp9zSRXF) for live support and to share your projects!
</Tip>
